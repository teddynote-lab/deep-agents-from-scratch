"""Research Tools.

This module provides search and content processing utilities for the research agent,
including web search capabilities and content summarization tools.
"""

from datetime import datetime

from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage, ToolMessage
from langchain_core.tools import InjectedToolArg, InjectedToolCallId, tool
from langgraph.prebuilt import InjectedState
from langgraph.types import Command
from pydantic import BaseModel, Field
from tavily import TavilyClient
from typing_extensions import Annotated, Literal

from deep_agents_from_scratch.prompts import SUMMARIZE_WEB_SEARCH
from deep_agents_from_scratch.state import DeepAgentState


def get_current_time() -> str:
    """Get current date in a human-readable format."""
    return datetime.now().strftime("%b %-d, %Y %H:%M:%S (%A)")


tavily_client = TavilyClient()


def run_web_search(
    search_query: str,
    max_results: int = 2,
    topic: Literal["general", "news", "finance"] = "general",
    include_raw_content: bool = True,
) -> dict:
    """Perform search using Tavily API for a single query.

    Args:
        search_query: Search query to execute
        max_results: Maximum number of results per query
        topic: Topic filter for search results
        include_raw_content: Whether to include raw webpage content

    Returns:
        Search results dictionary
    """
    result = tavily_client.search(
        search_query,
        max_results=max_results,
        include_raw_content=include_raw_content,
        topic=topic,
    )
    return result


# ìš”ì•½ì„ ìœ„í•œ LLM ì´ˆê¸°í™”
summarization_model = init_chat_model(
    model="anthropic:claude-haiku-4-5", temperature=0.0
)


class Summary(BaseModel):
    """Schema for webpage content summarization."""

    filename: str = Field(description="Name of the file to store.")
    summary: str = Field(description="Key learnings from the webpage.")


def summarize_webpage_contents(webpage_contents: list[str]) -> list[Summary]:
    """Summarize multiple webpage contents in parallel using batch processing.

    LangChainì˜ batch() ë©”ì„œë“œë¥¼ í™œìš©í•˜ì—¬ ì—¬ëŸ¬ ì›¹íŽ˜ì´ì§€ ì½˜í…ì¸ ë¥¼ ë³‘ë ¬ë¡œ ìš”ì•½

    Args:
        webpage_contents: List of raw webpage contents to summarize

    Returns:
        List of Summary objects with filename and summary for each content
    """
    if not webpage_contents:
        return []

    # êµ¬ì¡°í™”ëœ ì¶œë ¥ ëª¨ë¸ ì„¤ì •
    structured_model = summarization_model.with_structured_output(Summary)

    # ê° ì½˜í…ì¸ ì— ëŒ€í•œ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„± (batch ìž…ë ¥ í˜•ì‹)
    batch_inputs = [
        [
            HumanMessage(
                content=SUMMARIZE_WEB_SEARCH.format(
                    webpage_content=content, date=get_current_time()
                )
            )
        ]
        for content in webpage_contents
    ]

    try:
        # batch() ë©”ì„œë“œë¡œ ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰
        summaries = structured_model.batch(batch_inputs)
        return summaries

    except Exception as e:
        # ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ìš”ì•½ ê°ì²´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        print(f"Batch processing failed: {e}, falling back to sequential processing")
        return [
            Summary(
                filename=f"search_result_{i}.md",
                summary=(content[:1000] + "..." if len(content) > 1000 else content),
            )
            for i, content in enumerate(webpage_contents)
        ]


def process_search_results(results: dict) -> list[dict]:
    """Process search results by summarizing content in parallel using batch processing.

    LangChainì˜ batch() ë©”ì„œë“œë¥¼ í™œìš©í•˜ì—¬ ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³‘ë ¬ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
    ìˆœì°¨ ì²˜ë¦¬ ëŒ€ë¹„ ì²˜ë¦¬ ì‹œê°„ì„ ëŒ€í­ ë‹¨ì¶•í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

    Args:
        results: Tavily search results dictionary

    Returns:
        List of processed results with summaries
    """
    search_results = results.get("results", [])

    if not search_results:
        return []

    # ëª¨ë“  raw_contentë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ (batch ìž…ë ¥ìš©)
    raw_contents = [result.get("raw_content", "") for result in search_results]

    # batch ë°©ì‹ìœ¼ë¡œ ëª¨ë“  ì½˜í…ì¸ ë¥¼ ë³‘ë ¬ ìš”ì•½ ì²˜ë¦¬ (summarize_webpage_contents í•¨ìˆ˜ í™œìš©)
    summary_objects = summarize_webpage_contents(raw_contents)

    # ìš”ì•½ ê²°ê³¼ì™€ ì›ë³¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ ìµœì¢… ê²°ê³¼ ìƒì„±
    processed_results = []
    for result, summary_obj in zip(search_results, summary_objects):
        processed_results.append(
            {
                "url": result["url"],
                "title": result["title"],
                "summary": summary_obj.summary,
                "filename": summary_obj.filename,
                "raw_content": result.get("raw_content", ""),
            }
        )

    return processed_results


@tool(parse_docstring=True)
def tavily_search(
    query: str,
    state: Annotated[DeepAgentState, InjectedState],
    tool_call_id: Annotated[str, InjectedToolCallId],
    max_results: Annotated[int, InjectedToolArg] = 1,
    topic: Annotated[
        Literal["general", "news", "finance"], InjectedToolArg
    ] = "general",
) -> Command:
    """ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ìƒì„¸í•œ ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ìž¥í•˜ë©´ì„œ ìµœì†Œí•œì˜ ì»¨í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.

    ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ì „ì²´ ì½˜í…ì¸ ë¥¼ íŒŒì¼ì— ì €ìž¥í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ì˜¤í”„ë¡œë”©ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    ì—ì´ì „íŠ¸ê°€ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” í•„ìˆ˜ ì •ë³´ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        query: ì‹¤í–‰í•  ê²€ìƒ‰ ì¿¼ë¦¬
        state: íŒŒì¼ ì €ìž¥ì„ ìœ„í•œ ì£¼ìž…ëœ ì—ì´ì „íŠ¸ ìƒíƒœ
        tool_call_id: ì£¼ìž…ëœ ë„êµ¬ í˜¸ì¶œ ì‹ë³„ìž
        max_results: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 1)
        topic: í† í”½ í•„í„° - 'general', 'news', ë˜ëŠ” 'finance' (ê¸°ë³¸ê°’: 'general')

    Returns:
        ì „ì²´ ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ìž¥í•˜ê³  ìµœì†Œí•œì˜ ìš”ì•½ì„ ì œê³µí•˜ëŠ” Command
    """
    # ê²€ìƒ‰ ì‹¤í–‰
    search_results = run_web_search(
        query,
        max_results=max_results,
        topic=topic,
        include_raw_content=True,
    )

    # ê²°ê³¼ ì²˜ë¦¬ ë° ìš”ì•½
    processed_results = process_search_results(search_results)

    # ê° ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ìž¥í•˜ê³  ìš”ì•½ ì¤€ë¹„
    files = state.get("files", {})
    saved_files = []
    summaries = []

    for i, result in enumerate(processed_results):
        # ìš”ì•½ì—ì„œ AIê°€ ìƒì„±í•œ íŒŒì¼ëª… ì‚¬ìš©
        filename = result["filename"]

        # ì „ì²´ ìƒì„¸ ì •ë³´ë¥¼ í¬í•¨í•œ íŒŒì¼ ì½˜í…ì¸  ìƒì„±
        file_content = f"""# Search Result: {result['title']}

**URL:** {result['url']}
**Query:** {query}
**Date:** {get_current_time()}

## Summary
{result['summary']}

## Raw Content
{result['raw_content'] if result['raw_content'] else 'No raw content available'}
"""

        files[filename] = file_content
        saved_files.append(filename)
        summaries.append(f"- {filename}: {result['summary']}...")

    # ë„êµ¬ ë©”ì‹œì§€ë¥¼ ìœ„í•œ ìµœì†Œí•œì˜ ìš”ì•½ ìƒì„± - ìˆ˜ì§‘ëœ ë‚´ìš©ì— ì§‘ì¤‘
    summary_text = f"""ðŸ” Found {len(processed_results)} result(s) for '{query}':

{chr(10).join(summaries)}

Files: {', '.join(saved_files)}
ðŸ’¡ Use read_file() to access full details when needed."""

    return Command(
        update={
            "files": files,
            "messages": [ToolMessage(summary_text, tool_call_id=tool_call_id)],
        }
    )


@tool(parse_docstring=True)
def think_tool(reflection: str) -> str:
    """Tool for strategic reflection on research progress and decision-making.

    Use this tool after each search to analyze results and plan next steps systematically.
    This creates a deliberate pause in the research workflow for quality decision-making.

    When to use:
    - After receiving search results: What key information did I find?
    - Before deciding next steps: Do I have enough to answer comprehensively?
    - When assessing research gaps: What specific information am I still missing?
    - Before concluding research: Can I provide a complete answer now?
    - How complex is the question: Have I reached the number of search limits?

    Reflection should address:
    1. Analysis of current findings - What concrete information have I gathered?
    2. Gap assessment - What crucial information is still missing?
    3. Quality evaluation - Do I have sufficient evidence/examples for a good answer?
    4. Strategic decision - Should I continue searching or provide my answer?

    Args:
        reflection: Your detailed reflection on research progress, findings, gaps, and next steps

    Returns:
        Confirmation that reflection was recorded for decision-making
    """
    return f"Reflection recorded: {reflection}"
